{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b5787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy scipy matplotlib soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import soundfile as sf\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "file_name='DNote'\n",
    "\n",
    "# Load the audio file\n",
    "# file_path = 'RecordingTest.mp3'\n",
    "file_path = file_name+'.mp3'\n",
    "signal, sample_rate = sf.read(file_path)\n",
    "\n",
    "# If the audio file is stereo, take only one channel\n",
    "if signal.ndim > 1:\n",
    "    signal = signal[:, 0]\n",
    "\n",
    "# Calculate the time axis\n",
    "time = np.linspace(0, len(signal) / sample_rate, num=len(signal))\n",
    "\n",
    "# Perform Fourier transform\n",
    "N = len(signal)\n",
    "yf = fft(signal)\n",
    "xf = fftfreq(N, 1 / sample_rate)\n",
    "\n",
    "# Filter the frequency data to limit between 0 and 5k Hz\n",
    "freq_limit = 2000\n",
    "indices = np.where((xf >= 0) & (xf <= freq_limit))\n",
    "xf_limited = xf[indices]\n",
    "yf_limited = 2.0 / N * np.abs(yf[indices])\n",
    "\n",
    "# Create a subplot grid\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Time Domain', 'Frequency Spectrum'))\n",
    "\n",
    "# Plot the original signal in time domain using 'sampled' mode\n",
    "fig.add_trace(go.Scatter(x=time, y=signal, mode='lines', name='Time Domain', line_simplify=True), row=1, col=1)\n",
    "\n",
    "# Plot the frequency spectrum using 'sampled' mode\n",
    "fig.add_trace(go.Scatter(x=xf_limited, y=yf_limited, mode='lines', name='Frequency Spectrum', line_simplify=True), row=1, col=2)\n",
    "\n",
    "# Add titles and layout\n",
    "fig.update_layout(\n",
    "    title='Audio Signal and Frequency Spectrum',\n",
    "    showlegend=False,\n",
    "    legend=dict(x=0.5, y=1.1, xanchor='center', orientation='h')\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Time [s]', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Amplitude', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Frequency [Hz]', row=1, col=2, range=[0, freq_limit])\n",
    "fig.update_yaxes(title_text='Magnitude', row=1, col=2)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Reconstruct signal using different number of most important Fourier modes and save audio files\n",
    "\n",
    "# Focus on frequencies within 0 to 1 kHz\n",
    "freq_reconstruction_limit = 10000\n",
    "indices_reconstruction = np.where((xf >= 0) & (xf <= freq_reconstruction_limit))[0]\n",
    "\n",
    "# Define the number of modes to keep for reconstruction\n",
    "num_modes_list = [50,500,5000,50000,500000]\n",
    "\n",
    "# Part 3: Create a plot for each reconstructed signal comparing it to the original one\n",
    "comparison_figs = []\n",
    "\n",
    "for num_modes in num_modes_list:\n",
    "    # Sort the Fourier coefficients by magnitude and select the top num_modes indices\n",
    "    sorted_indices = np.argsort(np.abs(yf[indices_reconstruction]))[::-1][:num_modes]\n",
    "    important_indices = indices_reconstruction[sorted_indices]\n",
    "    \n",
    "    # Create a mask to keep only the most important frequencies\n",
    "    mask = np.zeros(N, dtype=bool)\n",
    "    mask[important_indices] = True\n",
    "    mask[-important_indices.size:] = True\n",
    "\n",
    "    # Apply the mask to the Fourier coefficients\n",
    "    yf_masked = yf * mask\n",
    "\n",
    "    # Perform the inverse Fourier transform to reconstruct the signal\n",
    "    signal_reconstructed = np.real(ifft(yf_masked))\n",
    "\n",
    "    # Save the reconstructed signal as an audio file\n",
    "    output_file = 'reconstructed_'+file_name+f'{num_modes}_modes.wav'\n",
    "    sf.write(output_file, signal_reconstructed, sample_rate)\n",
    "\n",
    "    # Print the status\n",
    "    print(f'Reconstructed signal with'+file_name+ '{num_modes} most important modes saved as {output_file}')\n",
    "    \n",
    "    # Create a comparison plot\n",
    "    comparison_fig = go.Figure()\n",
    "    comparison_fig.add_trace(go.Scatter(x=time, y=signal, mode='lines', name='Original Signal', line_simplify=True))\n",
    "    comparison_fig.add_trace(go.Scatter(x=time, y=signal_reconstructed, mode='lines', name=f'Reconstructed Signal ({num_modes} modes)', line_simplify=True))\n",
    "    comparison_fig.update_layout(\n",
    "        title=f'Original Signal vs. Reconstructed Signal ({num_modes} modes)',\n",
    "        xaxis_title='Time [s]',\n",
    "        yaxis_title='Amplitude',\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    comparison_figs.append(comparison_fig)\n",
    "\n",
    "# Show all comparison plots\n",
    "for comparison_fig in comparison_figs:\n",
    "    comparison_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d450989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
